{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "name": "FBMFOR_Chemometrics_Analysis.ipynb"
  }
 },
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "---\ntitle: \"Chemometric Analysis for Food Fraud Detection\"\nformat:\n  html:\n    code-fold: false\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd2c Chemometric Analysis Notebook\n## FBMFOR \u2014 Food Fraud Analysis\n**MSc Food Technology and Quality Assurance** | University of Reading\n\n---\n\nThis notebook provides a complete chemometric analysis pipeline for spectroscopic data (NMR, FTIR) used in food fraud detection. You will work through:\n\n1. **Data upload and exploration** \u2014 load your spectral data and metadata\n2. **Preprocessing** \u2014 baseline correction, normalisation, and derivatives\n3. **Principal Component Analysis (PCA)** \u2014 unsupervised exploration\n4. **Hierarchical Cluster Analysis (HCA)** \u2014 sample grouping\n5. **PLS-DA** \u2014 supervised classification\n6. **OPLS-DA** \u2014 orthogonal signal correction for enhanced discrimination\n\nEach section includes explanatory text describing the *what* and *why* of each step. You are encouraged to modify parameters and observe the effects.\n\n> **Data format:** CSV files with samples as rows and spectral variables (wavenumbers/chemical shifts) as columns. The first column should contain sample IDs, and a separate metadata CSV maps sample IDs to class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n\nRun this cell to install and import all required packages. On Google Colab, most are pre-installed; only `plotly` may need updating."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# INSTALL & IMPORT\n# ============================================================\n# Uncomment the next line if running on Colab and plotly is outdated\n# !pip install --upgrade plotly\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom scipy import signal, sparse\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\nfrom scipy.spatial.distance import pdist\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.model_selection import cross_val_predict, LeaveOneOut, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"\u2705 All packages imported successfully.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demo Dataset: Simulated Olive Oil FTIR\n\nThis section generates a **realistic simulated FTIR dataset** for olive oil authentication. The dataset mimics mid-infrared spectra (4000\u2013400 cm\u207b\u00b9) for three classes:\n\n- **Extra Virgin Olive Oil (EVOO)** \u2014 authentic\n- **Refined Olive Oil (ROO)** \u2014 lower grade, sometimes mislabelled\n- **Adulterated** \u2014 EVOO blended with hazelnut or sunflower oil\n\nKey spectral differences are introduced in regions known to be diagnostic:\n- ~1745 cm\u207b\u00b9 (carbonyl C=O stretch \u2014 ester linkage, differs with fatty acid profile)\n- ~2925 and ~2854 cm\u207b\u00b9 (C\u2013H stretching \u2014 related to chain length and saturation)\n- ~1160 cm\u207b\u00b9 (C\u2013O stretch \u2014 differs with triglyceride composition)\n- ~3005 cm\u207b\u00b9 (=C\u2013H stretch \u2014 indicator of unsaturation)\n\n> **Skip this section** if you want to upload your own data \u2014 proceed to Section 3."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# GENERATE SIMULATED OLIVE OIL FTIR DATA\n# ============================================================\nnp.random.seed(42)\n\n# Wavenumber axis (4000 to 400 cm-1, typical FTIR range)\nwavenumbers = np.linspace(4000, 400, 1800)\n\ndef gaussian_peak(x, centre, width, height):\n    \"\"\"Generate a Gaussian absorption peak.\"\"\"\n    return height * np.exp(-0.5 * ((x - centre) / width) ** 2)\n\ndef generate_spectrum(class_type, sample_idx):\n    \"\"\"Generate a simulated FTIR spectrum for a given oil class.\"\"\"\n    spectrum = np.zeros_like(wavenumbers)\n    \n    # Common peaks (all olive oils)\n    spectrum += gaussian_peak(wavenumbers, 2925, 30, 0.8)   # C-H asymmetric stretch\n    spectrum += gaussian_peak(wavenumbers, 2854, 25, 0.6)   # C-H symmetric stretch\n    spectrum += gaussian_peak(wavenumbers, 1745, 20, 0.9)   # C=O ester stretch\n    spectrum += gaussian_peak(wavenumbers, 1465, 15, 0.35)  # C-H bending\n    spectrum += gaussian_peak(wavenumbers, 1160, 25, 0.5)   # C-O stretch\n    spectrum += gaussian_peak(wavenumbers, 720, 12, 0.25)   # C-H rocking\n    \n    # Class-specific differences\n    if class_type == \"EVOO\":\n        spectrum += gaussian_peak(wavenumbers, 3005, 15, 0.30)  # Strong =C-H (high unsaturation)\n        spectrum += gaussian_peak(wavenumbers, 1650, 12, 0.08)  # Minor polyphenol-related\n    elif class_type == \"ROO\":\n        spectrum += gaussian_peak(wavenumbers, 3005, 15, 0.18)  # Weaker =C-H\n        spectrum += gaussian_peak(wavenumbers, 1745, 20, 0.05)  # Slightly different ester\n    elif class_type == \"Adulterated\":\n        spectrum += gaussian_peak(wavenumbers, 3005, 15, 0.12)  # Much weaker =C-H\n        spectrum += gaussian_peak(wavenumbers, 2925, 30, 0.10)  # Extra C-H (sunflower)\n        spectrum += gaussian_peak(wavenumbers, 1160, 25, 0.08)  # Different C-O profile\n    \n    # Add realistic noise + slight baseline drift\n    noise = np.random.normal(0, 0.012, len(wavenumbers))\n    baseline_drift = 0.02 * np.sin(wavenumbers / 800) + 0.01 * (wavenumbers / 4000)\n    spectrum += noise + baseline_drift\n    \n    return spectrum\n\n# Generate samples: 15 EVOO, 12 ROO, 10 Adulterated\nclasses = [\"EVOO\"] * 15 + [\"ROO\"] * 12 + [\"Adulterated\"] * 10\nsample_ids = [f\"{c}_{i+1:02d}\" for i, c in enumerate(classes)]\n\nspectra = np.array([generate_spectrum(c, i) for i, c in enumerate(classes)])\n\n# Create DataFrames\nspectral_columns = [f\"{w:.1f}\" for w in wavenumbers]\ndf_spectra = pd.DataFrame(spectra, columns=spectral_columns)\ndf_spectra.insert(0, \"Sample_ID\", sample_ids)\n\ndf_metadata = pd.DataFrame({\"Sample_ID\": sample_ids, \"Class\": classes})\n\nprint(f\"Generated {len(df_spectra)} spectra with {len(wavenumbers)} wavenumber points.\")\nprint(f\"Classes: {dict(zip(*np.unique(classes, return_counts=True)))}\")\nprint(f\"\\nSpectral data shape: {df_spectra.shape}\")\nprint(f\"Wavenumber range: {wavenumbers[-1]:.0f} \u2013 {wavenumbers[0]:.0f} cm\u207b\u00b9\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Upload (Your Own Data)\n\nUse this section to upload your own spectral data. You need **two CSV files**:\n\n1. **Spectral data** \u2014 rows = samples, columns = spectral variables (wavenumbers or chemical shifts). First column should be `Sample_ID`.\n2. **Metadata** \u2014 at minimum two columns: `Sample_ID` and `Class`.\n\n> **If using the demo dataset**, skip this cell \u2014 the data is already loaded above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# UPLOAD YOUR OWN DATA (skip if using demo dataset)\n# ============================================================\n# Uncomment and run this cell to upload your own files\n\n# from google.colab import files\n#\n# print(\"Upload your SPECTRAL DATA CSV:\")\n# uploaded = files.upload()\n# spectral_filename = list(uploaded.keys())[0]\n# df_spectra = pd.read_csv(spectral_filename)\n#\n# print(\"\\nUpload your METADATA CSV:\")\n# uploaded = files.upload()\n# metadata_filename = list(uploaded.keys())[0]\n# df_metadata = pd.read_csv(metadata_filename)\n#\n# print(f\"\\nSpectral data: {df_spectra.shape[0]} samples, {df_spectra.shape[1]-1} variables\")\n# print(f\"Metadata: {df_metadata.shape[0]} samples, columns: {list(df_metadata.columns)}\")\n# print(f\"Classes found: {df_metadata['Class'].value_counts().to_dict()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration\n\nBefore any analysis, it is essential to **visually inspect your raw spectra**. Look for:\n- Obvious outliers or failed measurements\n- Baseline drift (common in FTIR)\n- Differences in overall intensity between samples\n- Key absorption bands that differ between groups"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PREPARE DATA MATRICES\n# ============================================================\n# Extract numeric spectral matrix (X) and merge class labels\nX_raw = df_spectra.drop(columns=[\"Sample_ID\"]).values.astype(float)\nsample_ids = df_spectra[\"Sample_ID\"].values\nvariable_names = df_spectra.drop(columns=[\"Sample_ID\"]).columns.values\n\n# Try to interpret variable names as numeric (wavenumbers / chemical shifts)\ntry:\n    x_axis = np.array([float(v) for v in variable_names])\n    x_label = \"Wavenumber (cm\u207b\u00b9)\" if x_axis[0] > x_axis[-1] else \"Chemical shift (ppm)\"\nexcept ValueError:\n    x_axis = np.arange(X_raw.shape[1])\n    x_label = \"Variable index\"\n\n# Merge class labels\nmerged = df_spectra[[\"Sample_ID\"]].merge(df_metadata, on=\"Sample_ID\", how=\"left\")\nclass_labels = merged[\"Class\"].values\nunique_classes = np.unique(class_labels)\n\nprint(f\"Spectral matrix X: {X_raw.shape[0]} samples \u00d7 {X_raw.shape[1]} variables\")\nprint(f\"Classes: {list(unique_classes)}\")\nprint(f\"X-axis: {x_label}, range {x_axis.min():.1f} \u2013 {x_axis.max():.1f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# INTERACTIVE RAW SPECTRA PLOT\n# ============================================================\nfig = go.Figure()\ncolours = px.colors.qualitative.Set2\n\nfor i, cls in enumerate(unique_classes):\n    mask = class_labels == cls\n    for j, idx in enumerate(np.where(mask)[0]):\n        fig.add_trace(go.Scatter(\n            x=x_axis, y=X_raw[idx],\n            name=cls if j == 0 else None,\n            legendgroup=cls,\n            showlegend=(j == 0),\n            line=dict(color=colours[i % len(colours)], width=0.8),\n            hovertext=sample_ids[idx],\n            hoverinfo=\"text+y\",\n            opacity=0.7\n        ))\n\n# Reverse x-axis for FTIR (high to low wavenumber convention)\nif x_axis[0] > x_axis[-1]:\n    fig.update_xaxes(autorange=\"reversed\")\n\nfig.update_layout(\n    title=\"Raw Spectra by Class\",\n    xaxis_title=x_label,\n    yaxis_title=\"Absorbance / Intensity\",\n    template=\"plotly_white\",\n    height=500,\n    hovermode=\"closest\"\n)\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# SUMMARY STATISTICS & MISSING VALUES\n# ============================================================\nprint(\"=== Data Quality Check ===\")\nprint(f\"Missing values: {np.isnan(X_raw).sum()}\")\nprint(f\"Infinite values: {np.isinf(X_raw).sum()}\")\nprint(f\"\\nIntensity range: {X_raw.min():.4f} to {X_raw.max():.4f}\")\nprint(f\"Mean intensity:  {X_raw.mean():.4f} \u00b1 {X_raw.std():.4f}\")\n\n# Per-class means\nprint(\"\\n=== Per-Class Mean Intensity ===\")\nfor cls in unique_classes:\n    mask = class_labels == cls\n    print(f\"  {cls}: {X_raw[mask].mean():.4f} \u00b1 {X_raw[mask].std():.4f} (n={mask.sum()})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spectral Preprocessing\n\nRaw spectra typically contain artefacts that must be removed before multivariate analysis:\n\n- **Baseline drift** \u2014 gradual shift in the spectrum baseline due to scattering or instrument effects. Corrected using asymmetric least squares (ALS) smoothing or polynomial fitting.\n- **Intensity variation** \u2014 differences in overall signal intensity between samples due to pathlength or concentration differences. Corrected by normalisation (SNV, min-max, or area normalisation).\n- **Noise and band overlap** \u2014 high-frequency noise or overlapping peaks can be resolved using Savitzky-Golay derivatives, which also remove constant and linear baseline offsets.\n\n> **Key principle:** Always visualise the effect of each preprocessing step. Over-processing can destroy genuine chemical information."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PREPROCESSING FUNCTIONS\n# ============================================================\n\ndef baseline_als(y, lam=1e6, p=0.01, niter=10):\n    \"\"\"\n    Asymmetric Least Squares baseline correction (Eilers & Boelens, 2005).\n    \n    Parameters:\n        y     : spectrum (1D array)\n        lam   : smoothness parameter (larger = smoother baseline). Try 1e4 to 1e8.\n        p     : asymmetry parameter (smaller = baseline hugs lower envelope). Try 0.001 to 0.05.\n        niter : number of iterations\n    \"\"\"\n    L = len(y)\n    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L - 2))\n    w = np.ones(L)\n    for _ in range(niter):\n        W = sparse.spdiags(w, 0, L, L)\n        Z = W + lam * D.dot(D.transpose())\n        z = sparse.linalg.spsolve(Z, w * y)\n        w = p * (y > z) + (1 - p) * (y < z)\n    return z\n\n\ndef snv(X):\n    \"\"\"\n    Standard Normal Variate (SNV) normalisation.\n    Each spectrum is centred and scaled by its own mean and std.\n    Removes scatter effects (multiplicative and additive).\n    \"\"\"\n    X_snv = np.zeros_like(X)\n    for i in range(X.shape[0]):\n        X_snv[i] = (X[i] - np.mean(X[i])) / np.std(X[i])\n    return X_snv\n\n\ndef area_normalise(X):\n    \"\"\"Normalise each spectrum to unit area (total intensity = 1).\"\"\"\n    return X / np.abs(X).sum(axis=1, keepdims=True)\n\n\ndef minmax_normalise(X):\n    \"\"\"Scale each spectrum to [0, 1] range.\"\"\"\n    mins = X.min(axis=1, keepdims=True)\n    maxs = X.max(axis=1, keepdims=True)\n    return (X - mins) / (maxs - mins)\n\n\ndef savgol_derivative(X, window_length=15, polyorder=2, deriv=1):\n    \"\"\"\n    Savitzky-Golay derivative.\n    \n    Parameters:\n        window_length : must be odd, larger = more smoothing\n        polyorder     : polynomial order (2 or 3 typical)\n        deriv         : derivative order (1 = first, 2 = second)\n    \"\"\"\n    return signal.savgol_filter(X, window_length, polyorder, deriv=deriv, axis=1)\n\n\nprint(\"\u2705 Preprocessing functions defined.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Apply Preprocessing\n\nModify the settings below to experiment with different preprocessing combinations. A typical workflow for FTIR data is: **baseline correction \u2192 SNV \u2192 (optional) 1st derivative**.\n\nFor NMR data, you might skip baseline correction and use: **area normalisation \u2192 (optional) binning**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PREPROCESSING SETTINGS \u2014 MODIFY THESE\n# ============================================================\n\n# Step 1: Baseline correction\nAPPLY_BASELINE = True           # True / False\nBASELINE_LAMBDA = 1e6           # Smoothness: try 1e4 to 1e8\nBASELINE_P = 0.01               # Asymmetry: try 0.001 to 0.05\n\n# Step 2: Normalisation\nNORMALISATION = \"snv\"            # Options: \"snv\", \"area\", \"minmax\", \"none\"\n\n# Step 3: Savitzky-Golay derivative\nAPPLY_DERIVATIVE = False         # True / False\nSG_WINDOW = 15                   # Window length (must be odd)\nSG_POLYORDER = 2                 # Polynomial order\nSG_DERIV = 1                     # Derivative order: 1 or 2\n\n# ============================================================\n# APPLY PREPROCESSING PIPELINE\n# ============================================================\nX_processed = X_raw.copy()\n\n# Step 1: Baseline correction\nif APPLY_BASELINE:\n    print(\"Applying baseline correction (ALS)...\")\n    for i in range(X_processed.shape[0]):\n        bl = baseline_als(X_processed[i], lam=BASELINE_LAMBDA, p=BASELINE_P)\n        X_processed[i] = X_processed[i] - bl\n\n# Step 2: Normalisation\nif NORMALISATION == \"snv\":\n    print(\"Applying SNV normalisation...\")\n    X_processed = snv(X_processed)\nelif NORMALISATION == \"area\":\n    print(\"Applying area normalisation...\")\n    X_processed = area_normalise(X_processed)\nelif NORMALISATION == \"minmax\":\n    print(\"Applying min-max normalisation...\")\n    X_processed = minmax_normalise(X_processed)\nelse:\n    print(\"No normalisation applied.\")\n\n# Step 3: Derivative\nif APPLY_DERIVATIVE:\n    deriv_suffix = \"st\" if SG_DERIV == 1 else \"nd\"\n    print(f\"Applying Savitzky-Golay {SG_DERIV}{deriv_suffix} derivative...\")\n    X_processed = savgol_derivative(X_processed, SG_WINDOW, SG_POLYORDER, SG_DERIV)\n\nprint(f\"\\n\u2705 Preprocessing complete. Matrix shape: {X_processed.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# VISUALISE PREPROCESSING EFFECT\n# ============================================================\nfig = make_subplots(rows=2, cols=1, subplot_titles=(\"Before preprocessing\", \"After preprocessing\"),\n                    shared_xaxes=True, vertical_spacing=0.08)\n\nfor i, cls in enumerate(unique_classes):\n    mask = class_labels == cls\n    for j, idx in enumerate(np.where(mask)[0]):\n        fig.add_trace(go.Scatter(\n            x=x_axis, y=X_raw[idx], name=cls if j == 0 else None,\n            legendgroup=cls, showlegend=(j == 0),\n            line=dict(color=colours[i % len(colours)], width=0.6), opacity=0.6\n        ), row=1, col=1)\n        fig.add_trace(go.Scatter(\n            x=x_axis, y=X_processed[idx], name=cls if j == 0 else None,\n            legendgroup=cls, showlegend=False,\n            line=dict(color=colours[i % len(colours)], width=0.6), opacity=0.6\n        ), row=2, col=1)\n\nif x_axis[0] > x_axis[-1]:\n    fig.update_xaxes(autorange=\"reversed\")\n\nfig.update_layout(title=\"Preprocessing Comparison\", template=\"plotly_white\", height=700)\nfig.update_xaxes(title_text=x_label, row=2, col=1)\nfig.update_yaxes(title_text=\"Absorbance\", row=1, col=1)\nfig.update_yaxes(title_text=\"Preprocessed\", row=2, col=1)\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Principal Component Analysis (PCA)\n\nPCA is an **unsupervised** method that reduces the dimensionality of spectral data by finding directions (principal components) of maximum variance. It is typically the first step in chemometric analysis because it:\n\n- Reveals natural groupings (or lack thereof) in the data\n- Identifies outliers\n- Shows which spectral regions contribute most to variation (via loadings)\n- Helps determine how many latent variables are needed for supervised models\n\n> **Important:** PCA does not use class labels \u2014 any separation seen in the scores plot reflects genuine chemical differences captured by the spectral data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PCA \u2014 FIT AND EXPLORE\n# ============================================================\nN_COMPONENTS = 10  # Number of PCs to compute (adjust if needed)\n\n# Mean-centre the data (standard for PCA on spectral data)\nscaler = StandardScaler(with_std=False)  # Mean-centre only, no scaling\nX_mc = scaler.fit_transform(X_processed)\n\n# Fit PCA\npca = PCA(n_components=min(N_COMPONENTS, X_mc.shape[0], X_mc.shape[1]))\nscores = pca.fit_transform(X_mc)\nloadings = pca.components_\nexplained_var = pca.explained_variance_ratio_ * 100\n\nprint(f\"PCA fitted with {pca.n_components_} components.\")\nprint(f\"\\nExplained variance per PC:\")\nfor i, ev in enumerate(explained_var):\n    cumulative = explained_var[:i+1].sum()\n    bar = \"\u2588\" * int(ev)\n    print(f\"  PC{i+1:2d}: {ev:5.1f}% {bar}  (cumulative: {cumulative:.1f}%)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# SCREE PLOT\n# ============================================================\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\nfig.add_trace(go.Bar(\n    x=[f\"PC{i+1}\" for i in range(len(explained_var))],\n    y=explained_var,\n    name=\"Individual\",\n    marker_color=\"steelblue\"\n), secondary_y=False)\n\nfig.add_trace(go.Scatter(\n    x=[f\"PC{i+1}\" for i in range(len(explained_var))],\n    y=np.cumsum(explained_var),\n    name=\"Cumulative\",\n    mode=\"lines+markers\",\n    marker=dict(color=\"firebrick\"),\n    line=dict(color=\"firebrick\")\n), secondary_y=True)\n\nfig.update_layout(title=\"Scree Plot\", template=\"plotly_white\", height=400)\nfig.update_yaxes(title_text=\"Explained variance (%)\", secondary_y=False)\nfig.update_yaxes(title_text=\"Cumulative (%)\", secondary_y=True, range=[0, 105])\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PCA SCORES PLOT (interactive with 95% confidence ellipses)\n# ============================================================\nPC_X = 1  # Which PC on x-axis (1-indexed)\nPC_Y = 2  # Which PC on y-axis\n\nscores_df = pd.DataFrame({\n    \"Sample_ID\": sample_ids,\n    \"Class\": class_labels,\n    f\"PC{PC_X}\": scores[:, PC_X - 1],\n    f\"PC{PC_Y}\": scores[:, PC_Y - 1]\n})\n\nfig = px.scatter(\n    scores_df, x=f\"PC{PC_X}\", y=f\"PC{PC_Y}\",\n    color=\"Class\", hover_name=\"Sample_ID\",\n    title=f\"PCA Scores Plot: PC{PC_X} vs PC{PC_Y}\",\n    labels={\n        f\"PC{PC_X}\": f\"PC{PC_X} ({explained_var[PC_X-1]:.1f}%)\",\n        f\"PC{PC_Y}\": f\"PC{PC_Y} ({explained_var[PC_Y-1]:.1f}%)\"\n    },\n    color_discrete_sequence=px.colors.qualitative.Set2\n)\n\n# Add 95% confidence ellipses\nfor cls in unique_classes:\n    mask = class_labels == cls\n    pc_x = scores[mask, PC_X - 1]\n    pc_y = scores[mask, PC_Y - 1]\n    \n    if len(pc_x) < 3:\n        continue\n    \n    # Calculate ellipse parameters\n    cov = np.cov(pc_x, pc_y)\n    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n    angle = np.degrees(np.arctan2(eigenvectors[1, 1], eigenvectors[0, 1]))\n    chi2_val = 5.991  # 95% confidence for 2 DOF\n    \n    # Generate ellipse points\n    theta = np.linspace(0, 2 * np.pi, 100)\n    a = np.sqrt(eigenvalues[1] * chi2_val)\n    b = np.sqrt(eigenvalues[0] * chi2_val)\n    ellipse_x = a * np.cos(theta)\n    ellipse_y = b * np.sin(theta)\n    \n    # Rotate\n    cos_a, sin_a = np.cos(np.radians(angle)), np.sin(np.radians(angle))\n    rot_x = cos_a * ellipse_x - sin_a * ellipse_y + pc_x.mean()\n    rot_y = sin_a * ellipse_x + cos_a * ellipse_y + pc_y.mean()\n    \n    fig.add_trace(go.Scatter(\n        x=rot_x, y=rot_y, mode=\"lines\",\n        line=dict(dash=\"dash\", width=1),\n        showlegend=False, hoverinfo=\"skip\"\n    ))\n\nfig.update_layout(template=\"plotly_white\", height=550, width=700)\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PCA LOADINGS PLOT\n# ============================================================\nLOADING_PC = 1  # Which PC loadings to plot (1-indexed)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=x_axis, y=loadings[LOADING_PC - 1],\n    mode=\"lines\", name=f\"PC{LOADING_PC} loadings\",\n    line=dict(color=\"steelblue\")\n))\n\nfig.add_hline(y=0, line_dash=\"dash\", line_color=\"grey\")\n\nif x_axis[0] > x_axis[-1]:\n    fig.update_xaxes(autorange=\"reversed\")\n\nfig.update_layout(\n    title=f\"PC{LOADING_PC} Loadings ({explained_var[LOADING_PC-1]:.1f}% variance)\",\n    xaxis_title=x_label,\n    yaxis_title=\"Loading\",\n    template=\"plotly_white\",\n    height=400\n)\nfig.show()\n\nprint(f\"\\nTop contributing variables for PC{LOADING_PC}:\")\nabs_loadings = np.abs(loadings[LOADING_PC - 1])\ntop_idx = np.argsort(abs_loadings)[::-1][:10]\nfor idx in top_idx:\n    print(f\"  {variable_names[idx]:>10s}: {loadings[LOADING_PC-1][idx]:+.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Hotelling's T\u00b2 \u2014 Outlier Detection\n\nHotelling's T\u00b2 statistic identifies samples that are unusually far from the centre of the PCA model. Samples exceeding the 95% or 99% confidence limit may be outliers that distort subsequent analysis.\n\n> **Action:** If outliers are identified, investigate them. They may represent measurement errors, contamination, or genuinely unusual samples. Remove them only with justification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# HOTELLING'S T\u00b2 OUTLIER DETECTION\n# ============================================================\nfrom scipy.stats import f as f_dist\n\nN_PC_HOTELLING = 3  # Number of PCs to use for T\u00b2 calculation\n\nscores_subset = scores[:, :N_PC_HOTELLING]\ncov_inv = np.linalg.inv(np.cov(scores_subset.T))\nT2 = np.array([s @ cov_inv @ s.T for s in scores_subset])\n\n# F-distribution critical values for 95% and 99% confidence\nn = X_mc.shape[0]\np = N_PC_HOTELLING\nT2_95 = (p * (n - 1) * (n + 1)) / (n * (n - p)) * f_dist.ppf(0.95, p, n - p)\nT2_99 = (p * (n - 1) * (n + 1)) / (n * (n - p)) * f_dist.ppf(0.99, p, n - p)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=list(range(n)), y=T2,\n    mode=\"markers+text\", text=sample_ids,\n    textposition=\"top center\", textfont=dict(size=8),\n    marker=dict(\n        color=[colours[list(unique_classes).index(c) % len(colours)] for c in class_labels],\n        size=8\n    ),\n    hovertext=sample_ids, name=\"Samples\"\n))\n\nfig.add_hline(y=T2_95, line_dash=\"dash\", line_color=\"orange\",\n              annotation_text=\"95% limit\", annotation_position=\"top right\")\nfig.add_hline(y=T2_99, line_dash=\"dash\", line_color=\"red\",\n              annotation_text=\"99% limit\", annotation_position=\"top right\")\n\nfig.update_layout(\n    title=f\"Hotelling's T\u00b2 (based on {N_PC_HOTELLING} PCs)\",\n    xaxis_title=\"Sample index\",\n    yaxis_title=\"T\u00b2\",\n    template=\"plotly_white\",\n    height=400\n)\nfig.show()\n\n# Report outliers\noutliers_95 = sample_ids[T2 > T2_95]\noutliers_99 = sample_ids[T2 > T2_99]\nprint(f\"Samples exceeding 95% limit: {list(outliers_95) if len(outliers_95) > 0 else 'None'}\")\nprint(f\"Samples exceeding 99% limit: {list(outliers_99) if len(outliers_99) > 0 else 'None'}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hierarchical Cluster Analysis (HCA)\n\nHCA is another **unsupervised** method that groups samples based on their similarity. Unlike PCA, it produces a **dendrogram** \u2014 a tree-like diagram showing how samples cluster together. This is useful for:\n\n- Confirming groupings seen in PCA\n- Identifying sub-groups within a class\n- Assessing how well different classes separate\n\n**Key parameters:**\n- **Distance metric** \u2014 how similarity is measured (Euclidean, correlation, cosine)\n- **Linkage method** \u2014 how clusters are merged (Ward's is generally recommended for spectral data)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# HIERARCHICAL CLUSTER ANALYSIS\n# ============================================================\nDISTANCE_METRIC = \"euclidean\"   # Options: \"euclidean\", \"correlation\", \"cosine\"\nLINKAGE_METHOD = \"ward\"          # Options: \"ward\", \"complete\", \"average\", \"single\"\n# Note: Ward's method requires Euclidean distance\n\n# Compute linkage on preprocessed data\nZ = linkage(X_processed, method=LINKAGE_METHOD, metric=DISTANCE_METRIC)\n\n# Create colour map for classes\nclass_colour_map = {cls: colours[i % len(colours)] for i, cls in enumerate(unique_classes)}\n\n# Plot dendrogram\nfig, ax = plt.subplots(figsize=(14, 5))\ndend = dendrogram(\n    Z, labels=sample_ids, leaf_rotation=90, leaf_font_size=8,\n    ax=ax, color_threshold=0\n)\n\n# Colour leaf labels by class\nxlbls = ax.get_xmajorticklabels()\nfor lbl in xlbls:\n    sample = lbl.get_text()\n    idx = list(sample_ids).index(sample)\n    lbl.set_color(class_colour_map[class_labels[idx]])\n\nax.set_title(f\"HCA Dendrogram ({LINKAGE_METHOD} linkage, {DISTANCE_METRIC} distance)\")\nax.set_ylabel(\"Distance\")\n\n# Add legend\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor=class_colour_map[c], label=c) for c in unique_classes]\nax.legend(handles=legend_elements, loc=\"upper right\")\n\nplt.tight_layout()\nplt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Partial Least Squares Discriminant Analysis (PLS-DA)\n\nPLS-DA is a **supervised** method that finds latent variables maximising the covariance between the spectral data (X) and the class labels (Y). Unlike PCA, it uses class information to find the most discriminating directions in spectral space.\n\n**Key considerations:**\n- The number of latent variables (LVs) must be optimised by cross-validation to avoid overfitting\n- **VIP scores** (Variable Importance in Projection) identify which spectral regions drive classification\n- Always validate with cross-validation \u2014 never rely on calibration performance alone\n\n> **Overfitting warning:** PLS-DA can easily overfit, especially with many more variables than samples (the typical case for spectral data). Cross-validation is essential."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PLS-DA: ENCODE CLASSES AND SELECT NUMBER OF LVs\n# ============================================================\nMAX_LV = 10  # Maximum number of LVs to test\n\n# Encode class labels as dummy matrix (one-hot for multiclass)\nle = LabelEncoder()\ny_encoded = le.fit_transform(class_labels)\n\n# For multiclass: create dummy Y matrix\nn_classes = len(unique_classes)\nY_dummy = np.zeros((len(y_encoded), n_classes))\nfor i, y in enumerate(y_encoded):\n    Y_dummy[i, y] = 1\n\n# Cross-validation to find optimal number of LVs\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = []\n\nfor n_lv in range(1, MAX_LV + 1):\n    pls = PLSRegression(n_components=n_lv, scale=True)\n    y_pred_cv = cross_val_predict(pls, X_processed, Y_dummy, cv=cv)\n    y_pred_class = le.inverse_transform(np.argmax(y_pred_cv, axis=1))\n    acc = accuracy_score(class_labels, y_pred_class)\n    cv_scores.append(acc)\n\noptimal_lv = np.argmax(cv_scores) + 1\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=list(range(1, MAX_LV + 1)), y=cv_scores,\n    mode=\"lines+markers\", marker=dict(color=\"steelblue\")\n))\nfig.add_vline(x=optimal_lv, line_dash=\"dash\", line_color=\"red\",\n              annotation_text=f\"Optimal: {optimal_lv} LVs\")\n\nfig.update_layout(\n    title=\"PLS-DA: Cross-Validation Accuracy vs Number of LVs\",\n    xaxis_title=\"Number of Latent Variables\",\n    yaxis_title=\"CV Accuracy\",\n    template=\"plotly_white\",\n    height=400,\n    yaxis=dict(range=[0, 1.05])\n)\nfig.show()\n\nprint(f\"\\nOptimal number of LVs: {optimal_lv} (CV accuracy: {cv_scores[optimal_lv-1]:.3f})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PLS-DA: FIT FINAL MODEL AND EVALUATE\n# ============================================================\nN_LV = optimal_lv  # Use optimal, or override manually\n\npls_final = PLSRegression(n_components=N_LV, scale=True)\npls_final.fit(X_processed, Y_dummy)\n\n# Cross-validated predictions\ny_pred_cv = cross_val_predict(pls_final, X_processed, Y_dummy, cv=cv)\ny_pred_class = le.inverse_transform(np.argmax(y_pred_cv, axis=1))\n\n# Confusion matrix\ncm = confusion_matrix(class_labels, y_pred_class, labels=le.classes_)\nfig = px.imshow(\n    cm, x=le.classes_, y=le.classes_,\n    labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n    text_auto=True, color_continuous_scale=\"Blues\",\n    title=f\"PLS-DA Confusion Matrix ({N_LV} LVs, 5-fold CV)\"\n)\nfig.update_layout(height=400, width=500)\nfig.show()\n\n# Classification report\nprint(\"\\nClassification Report (cross-validated):\")\nprint(classification_report(class_labels, y_pred_class))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PLS-DA SCORES PLOT\n# ============================================================\npls_scores = pls_final.x_scores_\n\nLV_X = 1  # LV for x-axis (1-indexed)\nLV_Y = 2  # LV for y-axis\n\nscores_df = pd.DataFrame({\n    \"Sample_ID\": sample_ids,\n    \"Class\": class_labels,\n    f\"LV{LV_X}\": pls_scores[:, LV_X - 1],\n    f\"LV{LV_Y}\": pls_scores[:, LV_Y - 1] if N_LV >= 2 else np.zeros(len(sample_ids))\n})\n\nfig = px.scatter(\n    scores_df, x=f\"LV{LV_X}\", y=f\"LV{LV_Y}\",\n    color=\"Class\", hover_name=\"Sample_ID\",\n    title=f\"PLS-DA Scores Plot: LV{LV_X} vs LV{LV_Y}\",\n    color_discrete_sequence=px.colors.qualitative.Set2\n)\nfig.update_layout(template=\"plotly_white\", height=550, width=700)\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# VIP SCORES (Variable Importance in Projection)\n# ============================================================\ndef calculate_vip(pls_model, X, Y):\n    \"\"\"\n    Calculate VIP scores for a fitted PLS model.\n    Variables with VIP > 1.0 are considered important.\n    VIP > 0.8 is sometimes used as a softer threshold.\n    \"\"\"\n    T = pls_model.x_scores_        # X scores\n    W = pls_model.x_weights_       # X weights\n    Q = pls_model.y_loadings_      # Y loadings\n    \n    p_vars = X.shape[1]  # number of variables\n    h = T.shape[1]       # number of components\n    \n    # Sum of squares of Y explained by each component\n    s = np.diag(T.T @ T @ Q.T @ Q)\n    s_total = s.sum()\n    \n    # VIP calculation\n    vip = np.zeros(p_vars)\n    for i in range(p_vars):\n        weight_sum = np.sum(s * (W[i, :] / np.linalg.norm(W[:, :], axis=0)) ** 2)\n        vip[i] = np.sqrt(p_vars * weight_sum / s_total)\n    \n    return vip\n\nvip_scores = calculate_vip(pls_final, X_processed, Y_dummy)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=x_axis, y=vip_scores,\n    mode=\"lines\", line=dict(color=\"steelblue\"),\n    hovertext=[f\"{v}: VIP={vip:.2f}\" for v, vip in zip(variable_names, vip_scores)]\n))\n\nfig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"red\",\n              annotation_text=\"VIP = 1.0 (important)\", annotation_position=\"top right\")\nfig.add_hline(y=0.8, line_dash=\"dot\", line_color=\"orange\",\n              annotation_text=\"VIP = 0.8\", annotation_position=\"top right\")\n\nif x_axis[0] > x_axis[-1]:\n    fig.update_xaxes(autorange=\"reversed\")\n\nfig.update_layout(\n    title=\"VIP Scores \u2014 Spectral Regions Driving Classification\",\n    xaxis_title=x_label,\n    yaxis_title=\"VIP Score\",\n    template=\"plotly_white\",\n    height=400\n)\nfig.show()\n\n# Top VIP variables\nprint(f\"\\nTop 10 most important spectral variables (VIP > 1.0):\")\ntop_vip_idx = np.argsort(vip_scores)[::-1][:10]\nfor idx in top_vip_idx:\n    print(f\"  {variable_names[idx]:>10s} cm\u207b\u00b9: VIP = {vip_scores[idx]:.3f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Orthogonal PLS-DA (OPLS-DA)\n\nOPLS-DA (Trygg & Wold, 2002) is an extension of PLS-DA that separates the variation in X into:\n\n- **Predictive** variation \u2014 correlated with the class labels (Y)\n- **Orthogonal** variation \u2014 structured variation unrelated to classes (e.g., batch effects, instrument drift)\n\nThis separation has two major advantages:\n1. The **predictive scores plot** often shows cleaner class separation than PLS-DA\n2. The **S-plot** (covariance vs correlation) identifies reliable biomarkers for class discrimination\n\n> **Note:** OPLS-DA is most effective for **two-class** comparisons. For multiclass problems, consider running pairwise OPLS-DA models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# OPLS-DA IMPLEMENTATION\n# ============================================================\n\nclass OPLSDA:\n    \"\"\"\n    Orthogonal PLS-DA (Trygg & Wold, 2002).\n    Separates X into predictive and orthogonal components.\n    \n    For two-class problems: use 1 predictive + n_ortho orthogonal components.\n    \"\"\"\n    \n    def __init__(self, n_ortho=1):\n        self.n_ortho = n_ortho\n        self.t_ortho_ = None      # Orthogonal scores\n        self.p_ortho_ = None      # Orthogonal loadings\n        self.w_ortho_ = None      # Orthogonal weights\n        self.t_pred_ = None       # Predictive scores\n        self.p_pred_ = None       # Predictive loadings\n        self.w_pred_ = None       # Predictive weights\n        self.pls_ = None          # Underlying PLS model\n        self.X_filtered_ = None   # X with orthogonal variation removed\n    \n    def fit(self, X, y):\n        \"\"\"\n        Fit OPLS-DA model.\n        X: preprocessed spectral matrix (n_samples, n_variables)\n        y: class labels as 1D array (will be encoded internally)\n        \"\"\"\n        # Mean-centre\n        self.X_mean_ = X.mean(axis=0)\n        self.y_mean_ = y.mean()\n        Xc = X - self.X_mean_\n        yc = (y - self.y_mean_).reshape(-1, 1)\n        \n        # Store for orthogonal correction\n        self.t_ortho_ = []\n        self.p_ortho_ = []\n        self.w_ortho_ = []\n        \n        X_filtered = Xc.copy()\n        \n        for i in range(self.n_ortho):\n            # PLS weight vector (first PLS component)\n            w = (X_filtered.T @ yc) / (yc.T @ yc)\n            w = w / np.linalg.norm(w)\n            \n            # PLS scores\n            t = X_filtered @ w\n            \n            # PLS loadings\n            p = (X_filtered.T @ t) / (t.T @ t)\n            \n            # Orthogonal weight\n            w_ortho = p - (w.T @ p) / (w.T @ w) * w\n            w_ortho = w_ortho / np.linalg.norm(w_ortho)\n            \n            # Orthogonal scores and loadings\n            t_ortho = X_filtered @ w_ortho\n            p_ortho = (X_filtered.T @ t_ortho) / (t_ortho.T @ t_ortho)\n            \n            # Remove orthogonal component\n            X_filtered = X_filtered - t_ortho @ p_ortho.T\n            \n            self.t_ortho_.append(t_ortho.ravel())\n            self.p_ortho_.append(p_ortho.ravel())\n            self.w_ortho_.append(w_ortho.ravel())\n        \n        self.t_ortho_ = np.array(self.t_ortho_).T\n        self.p_ortho_ = np.array(self.p_ortho_).T\n        self.w_ortho_ = np.array(self.w_ortho_).T\n        \n        # Fit PLS on filtered data\n        self.pls_ = PLSRegression(n_components=1, scale=False)\n        self.pls_.fit(X_filtered, yc)\n        \n        self.t_pred_ = self.pls_.x_scores_.ravel()\n        self.p_pred_ = self.pls_.x_loadings_.ravel()\n        self.w_pred_ = self.pls_.x_weights_.ravel()\n        self.X_filtered_ = X_filtered\n        \n        # Calculate R\u00b2 and Q\u00b2 for the predictive component\n        y_pred = self.pls_.predict(X_filtered)\n        ss_res = np.sum((yc - y_pred) ** 2)\n        ss_tot = np.sum(yc ** 2)\n        self.R2Y_ = 1 - ss_res / ss_tot\n        \n        return self\n    \n    def transform(self, X):\n        \"\"\"Apply orthogonal correction to new data.\"\"\"\n        Xc = X - self.X_mean_\n        for i in range(self.n_ortho):\n            t_ortho = Xc @ self.w_ortho_[:, i:i+1]\n            Xc = Xc - t_ortho @ self.p_ortho_[:, i:i+1].T\n        return Xc\n    \n    def predict(self, X):\n        \"\"\"Predict class for new data.\"\"\"\n        X_filt = self.transform(X)\n        return self.pls_.predict(X_filt).ravel() + self.y_mean_\n    \n    def s_plot_data(self):\n        \"\"\"\n        Generate S-plot data: covariance (p) vs correlation (pcorr).\n        Variables in the upper-right or lower-left corners of the S-plot\n        are reliable biomarkers.\n        \"\"\"\n        p = self.p_pred_  # Covariance (loadings)\n        \n        # Correlation between each variable and the predictive score\n        t = self.t_pred_\n        X_filt = self.X_filtered_\n        pcorr = np.array([np.corrcoef(X_filt[:, j], t)[0, 1] for j in range(X_filt.shape[1])])\n        \n        return p, pcorr\n\n\nprint(\"\u2705 OPLS-DA class defined.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Select Classes and Fit OPLS-DA\n\nOPLS-DA works best for **pairwise** comparisons. Select two classes to compare below. If you have more than two classes, you can repeat this analysis for each pair."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# OPLS-DA: SELECT CLASSES AND FIT\n# ============================================================\nCLASS_A = unique_classes[0]  # e.g., \"EVOO\"\nCLASS_B = unique_classes[2]  # e.g., \"Adulterated\"\nN_ORTHO = 1                  # Number of orthogonal components\n\nprint(f\"Comparing: {CLASS_A} vs {CLASS_B}\")\n\n# Subset data\nmask_ab = np.isin(class_labels, [CLASS_A, CLASS_B])\nX_ab = X_processed[mask_ab]\ny_ab = (class_labels[mask_ab] == CLASS_B).astype(float)  # 0 = CLASS_A, 1 = CLASS_B\nids_ab = sample_ids[mask_ab]\nlabels_ab = class_labels[mask_ab]\n\nprint(f\"Samples: {(y_ab==0).sum()} x {CLASS_A}, {(y_ab==1).sum()} x {CLASS_B}\")\n\n# Fit OPLS-DA\nopls = OPLSDA(n_ortho=N_ORTHO)\nopls.fit(X_ab, y_ab)\n\nprint(f\"\\nR\u00b2Y = {opls.R2Y_:.3f}\")\nprint(f\"Predictive score range: {opls.t_pred_.min():.3f} to {opls.t_pred_.max():.3f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# OPLS-DA SCORES PLOT: PREDICTIVE vs ORTHOGONAL\n# ============================================================\nopls_df = pd.DataFrame({\n    \"Sample_ID\": ids_ab,\n    \"Class\": labels_ab,\n    \"t_predictive\": opls.t_pred_,\n    \"t_orthogonal\": opls.t_ortho_[:, 0]\n})\n\nfig = px.scatter(\n    opls_df, x=\"t_predictive\", y=\"t_orthogonal\",\n    color=\"Class\", hover_name=\"Sample_ID\",\n    title=f\"OPLS-DA Scores: {CLASS_A} vs {CLASS_B} (R\u00b2Y = {opls.R2Y_:.3f})\",\n    labels={\"t_predictive\": \"Predictive score (t[1])\", \"t_orthogonal\": \"Orthogonal score (t_ortho[1])\"},\n    color_discrete_sequence=px.colors.qualitative.Set2\n)\nfig.add_vline(x=0, line_dash=\"dash\", line_color=\"grey\", opacity=0.5)\nfig.update_layout(template=\"plotly_white\", height=550, width=700)\nfig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# S-PLOT: IDENTIFY RELIABLE BIOMARKERS\n# ============================================================\np_cov, p_corr = opls.s_plot_data()\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=p_cov, y=p_corr,\n    mode=\"markers\",\n    marker=dict(\n        size=5, color=np.abs(p_corr),\n        colorscale=\"RdYlBu_r\", showscale=True,\n        colorbar=dict(title=\"|Correlation|\")\n    ),\n    hovertext=[f\"{v} cm\u207b\u00b9\" for v in variable_names],\n    hoverinfo=\"text\"\n))\n\n# Highlight significant variables (|pcorr| > 0.5 AND |p| in top percentile)\np_thresh = np.percentile(np.abs(p_cov), 90)\nsig_mask = (np.abs(p_corr) > 0.5) & (np.abs(p_cov) > p_thresh)\n\nif sig_mask.any():\n    fig.add_trace(go.Scatter(\n        x=p_cov[sig_mask], y=p_corr[sig_mask],\n        mode=\"markers+text\",\n        text=[f\"{v}\" for v in variable_names[sig_mask]],\n        textposition=\"top center\", textfont=dict(size=8),\n        marker=dict(size=10, color=\"red\", symbol=\"diamond\"),\n        name=\"Significant\", showlegend=True\n    ))\n\nfig.add_hline(y=0, line_dash=\"dash\", line_color=\"grey\", opacity=0.3)\nfig.add_vline(x=0, line_dash=\"dash\", line_color=\"grey\", opacity=0.3)\n\nfig.update_layout(\n    title=f\"S-Plot: {CLASS_A} vs {CLASS_B}\",\n    xaxis_title=\"Covariance p(cov)\",\n    yaxis_title=\"Correlation p(corr)\",\n    template=\"plotly_white\",\n    height=550, width=700\n)\nfig.show()\n\nprint(\"Variables in S-plot corners (reliable biomarkers):\")\nif sig_mask.any():\n    for idx in np.where(sig_mask)[0]:\n        direction = \"higher in \" + CLASS_B if p_cov[idx] > 0 else \"higher in \" + CLASS_A\n        print(f\"  {variable_names[idx]:>10s} cm\u207b\u00b9: p(cov)={p_cov[idx]:+.4f}, p(corr)={p_corr[idx]:+.3f} ({direction})\")\nelse:\n    print(\"  No variables met both thresholds. Try adjusting the criteria above.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Permutation Testing (Model Validation)\n\nPermutation testing is the gold standard for validating OPLS-DA models. The procedure:\n\n1. Randomly shuffle the class labels\n2. Fit a new OPLS-DA model on the shuffled data\n3. Repeat many times (e.g., 100\u2013200 permutations)\n4. Compare the real model's R\u00b2Y with the distribution of permuted R\u00b2Y values\n\nIf the real model is significantly better than the permuted models, the classification is genuine and not due to chance or overfitting.\n\n> **Note:** This can take a minute to run depending on the number of permutations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# PERMUTATION TEST FOR OPLS-DA\n# ============================================================\nN_PERMUTATIONS = 100  # Increase to 200 for publication-quality\n\nprint(f\"Running {N_PERMUTATIONS} permutations...\")\n\nperm_R2Y = []\nperm_corr = []  # Correlation between permuted and original y\n\nfor i in range(N_PERMUTATIONS):\n    # Shuffle y labels\n    y_perm = np.random.permutation(y_ab)\n    corr_with_original = np.abs(np.corrcoef(y_ab, y_perm)[0, 1])\n    \n    # Fit OPLS-DA on permuted data\n    opls_perm = OPLSDA(n_ortho=N_ORTHO)\n    opls_perm.fit(X_ab, y_perm)\n    \n    perm_R2Y.append(opls_perm.R2Y_)\n    perm_corr.append(corr_with_original)\n    \n    if (i + 1) % 20 == 0:\n        print(f\"  {i + 1}/{N_PERMUTATIONS} done...\")\n\nperm_R2Y = np.array(perm_R2Y)\nperm_corr = np.array(perm_corr)\n\n# Plot permutation results\nfig = go.Figure()\n\n# Permuted models\nfig.add_trace(go.Scatter(\n    x=perm_corr, y=perm_R2Y,\n    mode=\"markers\", name=\"Permuted\",\n    marker=dict(color=\"lightgrey\", size=6, line=dict(color=\"grey\", width=0.5))\n))\n\n# Real model (correlation = 1.0)\nfig.add_trace(go.Scatter(\n    x=[1.0], y=[opls.R2Y_],\n    mode=\"markers\", name=\"Real model\",\n    marker=dict(color=\"red\", size=14, symbol=\"star\")\n))\n\n# Regression line through permuted points\nfit_coef = np.polyfit(perm_corr, perm_R2Y, 1)\nx_line = np.linspace(0, 1, 50)\nfig.add_trace(go.Scatter(\n    x=x_line, y=np.polyval(fit_coef, x_line),\n    mode=\"lines\", name=\"Trend\", line=dict(dash=\"dash\", color=\"grey\")\n))\n\nfig.update_layout(\n    title=f\"Permutation Test ({N_PERMUTATIONS} permutations)\",\n    xaxis_title=\"Correlation with original y\",\n    yaxis_title=\"R\u00b2Y\",\n    template=\"plotly_white\",\n    height=500, width=600\n)\nfig.show()\n\n# Statistical test\np_value = (perm_R2Y >= opls.R2Y_).sum() / N_PERMUTATIONS\nprint(f\"\\nReal model R\u00b2Y: {opls.R2Y_:.3f}\")\nprint(f\"Permuted R\u00b2Y: {perm_R2Y.mean():.3f} \u00b1 {perm_R2Y.std():.3f}\")\nprint(f\"Permutation p-value: {p_value:.3f}\")\nif p_value < 0.05:\n    print(\"\u2705 Model is statistically significant (p < 0.05). Classification is genuine.\")\nelse:\n    print(\"\u26a0\ufe0f Model is NOT significant. Consider overfitting or insufficient class differences.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results\n\nDownload key results as CSV files for your report."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n# EXPORT KEY RESULTS\n# ============================================================\n\n# PCA scores\npca_export = pd.DataFrame(scores[:, :5], columns=[f\"PC{i+1}\" for i in range(5)])\npca_export.insert(0, \"Sample_ID\", sample_ids)\npca_export.insert(1, \"Class\", class_labels)\npca_export.to_csv(\"pca_scores.csv\", index=False)\n\n# PCA loadings\nloadings_export = pd.DataFrame(loadings[:5].T, columns=[f\"PC{i+1}\" for i in range(5)])\nloadings_export.insert(0, \"Variable\", variable_names)\nloadings_export.to_csv(\"pca_loadings.csv\", index=False)\n\n# VIP scores\nvip_export = pd.DataFrame({\"Variable\": variable_names, \"VIP\": vip_scores})\nvip_export.to_csv(\"vip_scores.csv\", index=False)\n\nprint(\"\u2705 Files saved:\")\nprint(\"  - pca_scores.csv\")\nprint(\"  - pca_loadings.csv\")\nprint(\"  - vip_scores.csv\")\n\n# Download in Colab\ntry:\n    from google.colab import files\n    files.download(\"pca_scores.csv\")\n    files.download(\"pca_loadings.csv\")\n    files.download(\"vip_scores.csv\")\nexcept ImportError:\n    print(\"\\n(Not running in Colab \u2014 files saved to current directory)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Reading\n\nJolliffe, I.T. (2002). *Principal Component Analysis*, 2nd ed. Springer.\n\nBarker, M. & Rayens, W. (2003). Partial least squares for discrimination. *Journal of Chemometrics*, 17(3), 166\u2013173.\n\nTrygg, J. & Wold, S. (2002). Orthogonal projections to latent structures (O-PLS). *Journal of Chemometrics*, 16(3), 119\u2013128.\n\nWiklund, S. et al. (2008). Visualization of GC/TOF-MS-based metabolomics data for identification of biochemically interesting compounds using OPLS class models. *Analytical Chemistry*, 80(1), 115\u2013122.\n\nChong, I.G. & Jun, C.H. (2005). Performance of some variable selection methods when multicollinearity is present. *Chemometrics and Intelligent Laboratory Systems*, 78(1\u20132), 103\u2013112.\n\nEilers, P.H.C. & Boelens, H.F.M. (2005). Baseline correction with asymmetric least squares smoothing. Leiden University Medical Centre report.\n\nBarnes, R.J., Dhanoa, M.S. & Lister, S.J. (1989). Standard normal variate transformation and de-trending of near-infrared diffuse reflectance spectra. *Applied Spectroscopy*, 43(5), 772\u2013777.\n\n---\n*Notebook prepared for FBMFOR \u2014 Food Fraud Analysis, University of Reading*"
   ]
  }
 ]
}